DATA - ML ALGORITHA REQUIRED DATA TO LEARN
FEATURES - MEASURABLE CHARESTRCTICS OF DATA USED AS INPUT
LABELS - IT IS CORRRECT ANSWER
TRAINED DATA - THE LABELED USED TO TRAIN ML MODEL
MODEL - MATHEMATICAL OR COMPUTATIONAL REPRESANTION OFTHE RELATIONSHIP BETWEEN INPUT AND OUTPUT 
TRAINING - PROCESS OF FITTING ML. TO ADJUST INTERNAL PARAMETERS TO MINIMISE THE ERROR 
EVALUATION - AFTER MODEL IS TRAINED, USED TO MAKE PREDICTIONS
VALIDATION - DURING THE TRAINING PROCESS A VALIDATION SET CAN BE USED TO MONITOR THE MODEL
OVERFITTING - WHEN A MODEL LEARNS THE TRAINING DATA TOO WELL AND PERFORMS POORLY ON NEW DATA
UNDERFITTING - WHEN A MODEL IS TOO SIMPLE AND FAIS TO CAPTURE UNDERLAYING PATTERNS

CLASSIFICATION
RANDOM-FOREST - METHOD USING MULTIPLE DECISION TREES TO CLASSIFY DATA AND REDUCE OVERFITTING
DECISION TREES - BUILDS A TREE LIKE MODEL TO CLASSIFY DATA BASED ON FEATURE CONDITIONS AND THEIR OUTCOMES
LOGISTIC REGRESSION - PREDICT BINARY OUTCOMES BY FITTING LOGISTIC FUNCTION TO INPUT DATA
SUPPORT VECTOR MACHINES - SEPRATES DATA POINT INTO DIFFRENT CLASSES 
K-NEAREST - CLASSIFIES DATA BASED ON THE DATA MAJORITY ITS K-NEAREST NEGIGHBOURS IN FEATURE SPACE

REGRESSION
LINEAR - PREDICT A CONTINOUS TARGET VARIABLE BY FITTING LINEAR EQUATIONS
RIDGE - A VARAITION OF LINEAR REGRESSION THAT ADDS A PENALTY TERM BASED ON ABSLOUTE VALUES OF COEFFICENTS
TREES - UTLIZES A TREE MODEL TO PREDICT COUNTINOUS VALUE BY PARTINATIONG THE DATA INTO SUBSETS
NON-LINAER - PREDICT A CONTINUES TARGET VARABLE USING NON LINEAR FUNCTION
BAYESIN LINEAR - INCORORATES BAYESIAN PRINCPLE TO ESTIMATE MODEL PARAMETERS AND MAKE PREDICTIONS
POLYNOMIAL - FITS POLYNOMIAL EQUATION TO THE INPUT DATA TO PREDICT A COUNTINOUS TARGET

CLUSTRING
K-MEANS - PARTITION DATA INTO'K' CLUSTER BY MINIMISING THER SUM OF SQURED DISTANCES BETWEEN DATA POINTS AND THEIR `CLUSTER CENTERS
MEAN SHIFT - NON PARAMETRIC TECHNIQUE THAT SHIFT DATA POINTS TOWARDS THE MODE OF THEIR LOCAL DENSITY TO FIND CLUSTERS
DBSCAN - DENSITY-BASED ALGORITHAM THAT GROUPS DATAPOINT BASED ON THIER DENSITY AND IDENTITES NOISE POINTS AS WELL
AFFINITY PROPGATION - DATA POINTS EXCHANGE MESSAGES TO DETERMINE EXEMPLARS(CLUSTER CENTERS) REPRESNTING DISTINCT GROUPS

Underfitting And Overfitting: If Our Algorithm Works Well With The Training Dataset But Not Well With Test Dataset, Then Such Problem Is Called Overfitting. And If Our Algorithm Does Not Perform Well Even With Training Dataset, Then Such Problem Is Called Underfitting.